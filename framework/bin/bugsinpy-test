#!/bin/bash

usage="-w work_dir
             The working directory to run the test. Default will be the current directory.
       -t single_test
             Run single test from input. Default will run the test case that relevant from bugs. Format for pytest: <test_file_path>::<test_method>. Format for unittest: <test_file_path_without.py>.<test_class>.<test_method> . Use bugsinpy-info to get the information about the project.
       -a
             Run all test case in the project. Default will run the test case that relevant from bugs
       -r
             Run the test case that relevant from bugs (Default)
       -s
             Run single test without re-compile(source file not changed)
       -j cpu
             Run all test case in parallel. Only works with -a option. Default is 1.
"

## Add path settings
export PYTHONNOUSERSITE=1

## Add Skip re-compile(for single directory test without source file changed.)
skip_build="0"
run_all="0"
relevant="0"
parallel_job="1"
for arg in "$@"; do
  case $arg in
    -[h?] | --help)
      cat <<-____HALP
          Usage: ${0##*/} [ --help ]
          $usage
____HALP
      exit 0
      ;;
  esac
done

single_test=""
###Read the flag of checkout
while getopts t:w:j:ars flag
do
   case "${flag}" in
      w) work_dir=${OPTARG};;
      t) single_test=${OPTARG};;
      j) parallel_job=${OPTARG};;
      a) run_all="1";;
      r) relevant="1";;
      s) skip_build="1";;
   esac
done

###Update the work directory
if [ "$work_dir" == "" ]; then 
   work_dir=$(pwd)
fi

if [[ $work_dir == */ ]]; then 
   temp_work_dir="$work_dir"
   work_dir=${temp_work_dir::-1}
fi

if [[ ! -e "$work_dir/bugsinpy_run_test.sh" ]]; then
   echo "This is not a checkout project folder"
   exit 1
fi

if [[ ! -e "$work_dir/bugsinpy_compile_flag" ]]; then
   echo "You have not compile this project"
   exit 1
fi

if [[ "$relevant" == "1" ]]; then
   run_all="0"
   single_test=""
fi

###Activate environment
cd "$work_dir"
default_conda_path=$HOME/anaconda3
conda_path="${CONDA_PATH:-$default_conda_path}"
source $conda_path/etc/profile.d/conda.sh
# Generate unique hash for the current enviroment
bug_python_version=$(grep -o "3\..\.." "bugsinpy_bug.info")
conda_env_name="$(grep -oP "(?<=project_name=).*" bugsinpy_bug.info)_$(grep -oP "(?<=bug_id=).*" bugsinpy_bug.info)"
project_name=$(grep -oP "(?<=project_name=).*" bugsinpy_bug.info)
bug_id=$(grep -oP "(?<=bug_id=).*" bugsinpy_bug.info)

if ! conda activate $conda_env_name; then
   echo "conda env not found, please run bugsinpy-compile first"
   exit 1
fi

if [[ $project_name == "matplotlib" ]]; then
   export MPLLOCALFREETYPE=1
fi

if [[ "$skip_build" == "0" ]]; then
   echo "Running install script..."
   ###Read and run setup.sh to apply the source change
   run_setup_all=""
   if [[ -f "bugsinpy_install.sh" ]]; then
      DONE=false
      until $DONE ;do
      read || DONE=true
         run_setup_all+="$REPLY;"
         echo $REPLY
      done < "bugsinpy_install.sh"
   fi

   IFS=';' read -r -a run_setup <<< "$run_setup_all"

   for index in "${!run_setup[@]}"
   do
      run_setup_trail=${run_setup[index]} 
      run_setup_now=$(echo $run_setup_trail | sed -e 's/\r//g')
      MPLLOCALFREETYPE=1 $run_setup_now
   done
else
   echo "[INFO] Skip install due to -s (skip build) flag (no-source file changed)."
fi

pytest="0"
#read file run_test.sh
run_command_all=""
DONE=false
until $DONE ;do
read || DONE=true
if [ "$REPLY" != "" ]; then
   run_command_all+="$REPLY;"
   if [[ "$REPLY" == *"pytest"* || "$REPLY" == *"py.test"* ]]; then
      pytest="1"
   fi
   # echo $REPLY
fi
done < "bugsinpy_run_test.sh"
IFS=';' read -r -a run_command <<< "$run_command_all"

rm -f "bugsinpy_fail.txt"
rm -f "bugsinpy_test.txt"
rm -f "bugsinpy_alltest.txt"
rm -f "bugsinpy_singletest.txt"

final_result=0

if [[ "$run_all" == "0" && "$single_test" == "" ]]; then
      #run every command on the run_test.sh
      run_command_filter=""
      echo "Run related tests..."
      for index in "${!run_command[@]}"
      do
         run_command_trail=${run_command[index]} 
         run_command_now=$(echo $run_command_trail | sed -e 's/\r//g')
      
         res_first=$($run_command_now 2>&1)
         test_result=$?
         echo "$run_command_now: $test_result"

         if [[ $test_result -ne 0 ]]; then
            final_result=1
         fi

         if [[ ${res_first##*$'\n'} == *"OK"* || ${res_first##*$'\n'} == *"pass"* || $res_first == *"passed"* || $res_first == *"OK "* ]]; then
            run_command_filter+="$run_command_now;"
         fi
         echo "BugsInPy test: $run_command_now: $test_result" &>>"bugsinpy_test.txt"
         echo "$res_first" &>>"bugsinpy_test.txt"
      done
elif [[ "$run_all" == "1" ]]; then
   echo "Run every test..."
   if [[ -f "bugsinpy_alltest_result.json" ]]; then
      rm "bugsinpy_alltest_result.json"
   fi
   if [[ "$pytest" == "1" ]]; then
      if [[ "$project_name" == "ansible" ]]; then
         echo "python -m pytest test/units/" &>>"bugsinpy_alltest.txt"
         PYTHONPATH=./lib python -m pytest test/units/ --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
               --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
      elif [[ $project_name == "fastapi" ]]; then
         echo "python -m pytest" &>>"bugsinpy_alltest.txt"
         PYTHONPATH=./docs/src python -m pytest --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
               --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
      elif [[ "$project_name" == "httpie" && $bug_id == "5" ]]; then
         echo "python -m pytest test/units/" &>>"bugsinpy_alltest.txt"
         python -m pytest tests/tests.py --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
               --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
      elif [[ "$project_name" == "httpie" ]]; then
         echo "python -m pytest tests/" &>>"bugsinpy_alltest.txt"
         python -m pytest tests/ --ignore tests/test_ssl.py --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
               --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
      elif [[ "$project_name" == "luigi" ]]; then
         echo "python -m pytest" &>>"bugsinpy_alltest.txt"
         python -m pytest test --ignore test/task_serialize_test.py --ignore test/_mysqldb_test.py \
               --ignore test/contrib/azureblob_test.py --ignore test/contrib/batch_test.py --ignore test/contrib/ecs_test.py \
               --ignore test/contrib/hdfs/ --ignore test/remote_scheduler_test.py --ignore test/rpc_test.py \
               --ignore test/scheduler_parameter_visibilities_test.py --ignore test/server_test.py \
               --ignore test/visualiser/visualiser_test.py \
               --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
               --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
      elif [[ "$project_name" == "pandas" ]]; then
         # if [[ "$bug_id" == "150" || "$bug_id" == "160" || "$bug_id" == "162" || "$bug_id" == "168" ]]; then
         #    echo "pytest pandas --ignore=pandas/tests/io/test_parquet.py" &>>"bugsinpy_alltest.txt"
         #    pytest pandas --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
         #       --json-report-omit log collectors warnings --ignore=pandas/tests/io/test_parquet.py \
         #       --ignore pandas/tests/io/test_common.py 2>&1 | tee -a "bugsinpy_alltest.txt"
         # else
            echo "pytest pandas" &>>"bugsinpy_alltest.txt"
            pytest pandas --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
               --json-report-omit log collectors warnings --ignore pandas/tests/io \
               2>&1 | tee -a "bugsinpy_alltest.txt"
         # fi
      elif [[ "$project_name" == "sanic" && $bug_id == "5" ]]; then
         echo "python -m pytest " &>>"bugsinpy_alltest.txt"
         python -m pytest --ignore tests/test_redirect.py --ignore tests/test_server_events.py --ignore tests/test_signal_handlers.py \
               --ignore tests/test_worker.py --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
               --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
      elif [[ "$project_name" == "tqdm" ]]; then
         echo "python -m pytest tqdm/tests/tests_*.py" &>>"bugsinpy_alltest.txt"
         python -m pytest tqdm/tests/tests_*.py --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
               --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
      else
         echo "python -m pytest" &>>"bugsinpy_alltest.txt"
         python -m pytest --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
               --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
      fi
   else
      echo "Run Unittest"
      ###Read bug.info file
      DONE=false
      until $DONE ;do
      read || DONE=true
      if [[ "$REPLY" == "test_file"* ]]; then
         test_file_all="$(cut -d'"' -f 2 <<< $REPLY)"
         IFS=';' read -r -a test_file <<< "$test_file_all"
         test_file_now=${test_file[0]}
      fi
      done < "bugsinpy_bug.info"

      echo "$test_file_now"
      stop_loop_test="0"
      access_test=""
      if [[ "$test_file_now" != "" ]]; then
         IFS='/' read -r -a test_file_ex <<< "$test_file_now"
      fi
      
      for index in "${!test_file_ex[@]}"
      do
      test_file_temp=${test_file_ex[index]}
      if [[ "$stop_loop_test" == "0" ]]; then
         if [[ "$test_file_temp" == *".py"* ]]; then
            stop_loop_test="1"
         else
            if [[ "$test_file_temp" == "test" || "$test_file_temp" == "tests" ]]; then
               stop_loop_test="1"
            fi 
            access_test+="$test_file_temp/"
         fi
      fi
      done

      echo "$access_test"
      echo "python -m unittest discover -s $access_test" | tee -a "bugsinpy_alltest.txt"
      python bugsinpy_unittest_runner.py $access_test 2>&1 | tee -a "bugsinpy_alltest.txt"
      # echo "python -m unittest discover $access_test"
      # if [[ "$project_name" == "black" ]]; then
      #    echo "python -m unittest discover -s $access_test"
      #    res_first=$(python -m unittest discover $access_test 2>&1)
      #    echo "$res_first"
      #    echo "python -m unittest discover $access_test" &>>"bugsinpy_alltest.txt"
      #    echo "$res_first" &>>"bugsinpy_alltest.txt"
      # else
      #    echo "unittest-parallel -t $work_dir -s $access_test -j $parallel_job"
      #    echo "unittest-parallel -t $work_dir -s $access_test -j $parallel_job" &>>"bugsinpy_alltest.txt"
      #    # res_first=$(python -m unittest discover $access_test 2>&1)
      #    unittest-parallel -t $work_dir -s $access_test -j $parallel_job 2>&1 | tee "bugsinpy_alltest.txt"
      #    #python -m unittest
      #    test_result=${PIPESTATUS[0]}
      # fi

      if [[ $test_result -ne 0 ]]; then
         final_result=1
      fi
   fi
elif [ "$single_test" != "" ]; then
   echo "Run $single_test..."
   if [[ "$pytest" == "1" ]]; then
      res_first=$(pytest $single_test 2>&1)
      test_result=$?
      echo "$single_test: $test_result"
      echo "BugsInPy test: $single_test: $test_result" &>>"bugsinpy_singletest.txt"
      echo "$res_first" &>>"bugsinpy_singletest.txt"
   else
      res_first=$(python -m unittest -q $single_test 2>&1)
      test_result=$?
      echo "$single_test: $test_result"
      echo "BugsInPy test: $single_test: $test_result" &>>"bugsinpy_singletest.txt"
      echo "$res_first" &>>"bugsinpy_singletest.txt"
   fi

   if [[ $test_result -ne 0 ]]; then
      final_result=1
   fi
fi

###Deactivate the environment
conda deactivate
exit $final_result