@inproceedings{mukherjee_fixing_2021,
	location = {Virtual Denmark},
	title = {Fixing dependency errors for Python build reproducibility},
	isbn = {978-1-4503-8459-9},
	url = {https://dl.acm.org/doi/10.1145/3460319.3464797},
	doi = {10.1145/3460319.3464797},
	eventtitle = {{ISSTA} '21: 30th {ACM} {SIGSOFT} International Symposium on Software Testing and Analysis},
	pages = {439--451},
	booktitle = {Proceedings of the 30th {ACM} {SIGSOFT} International Symposium on Software Testing and Analysis},
	publisher = {{ACM}},
	author = {Mukherjee, Suchita and Almanza, Abigail and Rubio-González, Cindy},
	urldate = {2023-07-17},
	date = {2021-07-11},
	langid = {english},
	keywords = {bugsinpy-reproduction},
}

@inproceedings{smytzek_sflkit_2022,
	location = {Singapore Singapore},
	title = {{SFLKit}: a workbench for statistical fault localization},
	isbn = {978-1-4503-9413-0},
	url = {https://dl.acm.org/doi/10.1145/3540250.3558915},
	doi = {10.1145/3540250.3558915},
	shorttitle = {{SFLKit}},
	eventtitle = {{ESEC}/{FSE} '22: 30th {ACM} Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
	pages = {1701--1705},
	booktitle = {Proceedings of the 30th {ACM} Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
	publisher = {{ACM}},
	author = {Smytzek, Marius and Zeller, Andreas},
	urldate = {2023-07-17},
	date = {2022-11-07},
	langid = {english},
}


@article{hirsch_systematic_2022,
	title = {A systematic literature review on benchmarks for evaluating debugging approaches},
	volume = {192},
	issn = {01641212},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0164121222001303},
	doi = {10.1016/j.jss.2022.111423},
	pages = {111423},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Hirsch, Thomas and Hofer, Birgit},
	urldate = {2023-07-17},
	date = {2022-10},
	langid = {english},
	file = {Full Text:C\:\\Users\\user\\Zotero\\storage\\2KKNDKI2\\Hirsch and Hofer - 2022 - A systematic literature review on benchmarks for e.pdf:application/pdf},
}


@article{lukasczyk_empirical_2023,
	title = {An empirical study of automated unit test generation for Python},
	volume = {28},
	issn = {1382-3256, 1573-7616},
	url = {https://link.springer.com/10.1007/s10664-022-10248-w},
	doi = {10.1007/s10664-022-10248-w},
	abstract = {Abstract
            
              Various mature automated test generation tools exist for statically typed programming languages such as Java. Automatically generating unit tests for dynamically typed programming languages such as Python, however, is substantially more difficult due to the dynamic nature of these languages as well as the lack of type information. Our
              Pynguin
              framework provides automated unit test generation for Python. In this paper, we extend our previous work on
              Pynguin
              to support more aspects of the Python language, and by studying a larger variety of well-established state of the art test-generation algorithms, namely {DynaMOSA}, {MIO}, and {MOSA}. Furthermore, we improved our
              Pynguin
              tool to generate regression assertions, whose quality we also evaluate. Our experiments confirm that evolutionary algorithms can outperform random test generation also in the context of Python, and similar to the Java world, {DynaMOSA} yields the highest coverage results. However, our results also demonstrate that there are still fundamental remaining issues, such as inferring type information for code without this information, currently limiting the effectiveness of test generation for Python.},
	pages = {36},
	number = {2},
	journaltitle = {Empirical Software Engineering},
	shortjournal = {Empir Software Eng},
	author = {Lukasczyk, Stephan and Kroiß, Florian and Fraser, Gordon},
	urldate = {2023-07-17},
	date = {2023-03},
	langid = {english},
	file = {Full Text:C\:\\Users\\user\\Zotero\\storage\\MJJ6VWE8\\Lukasczyk et al. - 2023 - An empirical study of automated unit test generati.pdf:application/pdf},
}


@article{akimova_survey_2021,
	title = {A Survey on Software Defect Prediction Using Deep Learning},
	volume = {9},
	issn = {2227-7390},
	url = {https://www.mdpi.com/2227-7390/9/11/1180},
	doi = {10.3390/math9111180},
	abstract = {Defect prediction is one of the key challenges in software development and programming language research for improving software quality and reliability. The problem in this area is to properly identify the defective source code with high accuracy. Developing a fault prediction model is a challenging problem, and many approaches have been proposed throughout history. The recent breakthrough in machine learning technologies, especially the development of deep learning techniques, has led to many problems being solved by these methods. Our survey focuses on the deep learning techniques for defect prediction. We analyse the recent works on the topic, study the methods for automatic learning of the semantic and structural features from the code, discuss the open problems and present the recent trends in the field.},
	pages = {1180},
	number = {11},
	journaltitle = {Mathematics},
	shortjournal = {Mathematics},
	author = {Akimova, Elena N. and Bersenev, Alexander Yu. and Deikov, Artem A. and Kobylkin, Konstantin S. and Konygin, Anton V. and Mezentsev, Ilya P. and Misilov, Vladimir E.},
	urldate = {2023-07-17},
	date = {2021-05-24},
	langid = {english},
	file = {Full Text:C\:\\Users\\user\\Zotero\\storage\\XL3LSGFX\\Akimova et al. - 2021 - A Survey on Software Defect Prediction Using Deep .pdf:application/pdf},
}